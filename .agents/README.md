# Kart Brain Agent Documentation

This directory contains persistent AI-focused documentation for the kart_brain workspace. It follows a two-layer system: **memory** (what agents read) and **enforcement** (what prevents bad work).

## Why This Exists

LLMs have no persistent memory between sessions. Every conversation starts fresh. This directory captures hard-won knowledge about the system so it doesn't have to be rediscovered each time.

## File Index

### Layer 1: Memory (What Agents Read)

| File | Purpose |
|---|---|
| `architecture.md` | Package structure, node graph, message types, topic map |
| `simulation.md` | Gazebo setup, known issues, rendering quirks, how to test |
| `vm_environment.md` | UTM VM specifics: SSH, sudo, installed packages, limitations |
| `orin_environment.md` | Jetson Orin specifics: hardware, ZED camera, live pipeline, known issues |
| `orin_flash_guide.md` | Step-by-step guide for flashing Orin to NVMe with JetPack 6.2.2 |
| `error_log.md` | Running log of mistakes and prevention mechanisms |
| `postmortems/` | Detailed failure analysis for significant errors |

### Layer 2: Enforcement

| File | Purpose |
|---|---|
| `../scripts/` | Workspace-level utility scripts |

## Workflow

1. **Before starting:** Read `AGENTS.md` (root) → relevant `.agents/` files
2. **During work:** Follow architecture conventions from `architecture.md`
3. **Before commit:** Build, verify, `git status` + `git diff`
4. **If something breaks:** Document in `error_log.md`, add prevention
5. **If recurring:** Create postmortem in `postmortems/`

## Environment-Specific Guides

| Environment | Doc | Connection |
|---|---|---|
| **Jetson Orin** (real hardware) | `orin_environment.md` | `ssh orin` (WiFi) or AnyDesk |
| **Jetson Orin** (flash/reinstall) | `orin_flash_guide.md` | USB-C from y540 to Orin |
| **y540 laptop** (flash host) | — | `ssh y540` (Robots_urjc WiFi, DHCP) |
| **UTM VM** (simulation) | `vm_environment.md` | `ssh utm` (192.168.65.2) |

## Key Principles

- **Document what was painful** — If you spent time debugging something, write it down
- **Cone class IDs matter** — The whole pipeline depends on consistent string IDs (`blue_cone`, `yellow_cone`, etc.)
- **BGR vs RGB** — OpenCV uses BGR, YOLO/PIL use RGB. Always verify channel order matches the declared encoding when passing images between systems
- **Check for stale processes** — Before launching ROS nodes, check if instances are already running
- **Odom is relative** — Gazebo odometry starts at (0,0), not at the world pose
- **No GPU in VM** — Everything renders via LLVMpipe. Keep resolutions low, disable shadows
